{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tweets_01-08-2021.csv\", index_col=\"id\", parse_dates=['date'])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "\n",
    "text = data.text.to_list()\n",
    "processed_tweets = []\n",
    "tokenizer = RegexpTokenizer('\\w+|\\S+')\n",
    "for tweet in text:\n",
    "    tweet = re.sub('(https?:[\\w\\/\\.\\d]+)|…|(^RT)|“|”|\"', \"\", tweet)\n",
    "    tweet = re.sub(\"&amp;?\", \"and\", tweet)\n",
    "    processed_tweets.append(tokenizer.tokenize(tweet.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all tweets are of different length, with most around 20\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot([len(tweet) for tweet in processed_tweets], bins=15)\n",
    "plt.xlabel(\"Tweet length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# keeping punctuation\n",
    "tok = Tokenizer(filters=\"\")\n",
    "tok.fit_on_texts(processed_tweets)\n",
    "\n",
    "sequences = []\n",
    "\n",
    "for seq in processed_tweets:\n",
    "    tokenized = tok.texts_to_sequences([seq])[0]\n",
    "    for i in range(2, len(tokenized)+1):\n",
    "        sequences.append(tokenized[:i])\n",
    "        \n",
    "total_words = len(tok.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating labels and padding\n",
    "labels = []\n",
    "for sequence in sequences:\n",
    "    labels.append(sequence.pop(-1))\n",
    "\n",
    "labels = np.array(labels)#.reshape(-1, 1)\n",
    "\n",
    "# we need to pad the tweets of lengths shorter than 100 so they are the same length\n",
    "# other strategies exist, like dropping long tweets to pad to 60\n",
    "# so we save space and computation time\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X = np.array(pad_sequences(\n",
    "    sequences, padding=\"post\"\n",
    "))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# either this, or use sparse_categorical_crossentropy\n",
    "# may be try a different data type?\n",
    "#label = tf.keras.utils.to_categorical(labels, num_classes=total_words, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "batch_size = 4096\n",
    "\n",
    "model1 = keras.Sequential([\n",
    "    layers.Embedding(input_dim=total_words, output_dim=256, mask_zero=True),\n",
    "    layers.LSTM(units=256, dropout=0.3, stateful=False),\n",
    "    layers.Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoints/model1.ckpt\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model1.fit(X, labels, \n",
    "          epochs=30, \n",
    "          batch_size=batch_size, \n",
    "          verbose=True, \n",
    "          use_multiprocessing=True, \n",
    "          workers=8,\n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a reverse dictionary for prediction\n",
    "id_to_word = {v:k for k,v in tok.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction funciton\n",
    "def predict_sequence(seed, length, model):\n",
    "    # how much to pad\n",
    "    max_len = len(X[0])\n",
    "    # final prediction sequence\n",
    "    output = seed + \" \"\n",
    "    # keep predicting until reach the length\n",
    "    for i in range(length): \n",
    "        # tokenize\n",
    "        tokenized = tok.texts_to_sequences([output])[0]\n",
    "        # pad\n",
    "        x = np.array(pad_sequences([tokenized], padding=\"post\", maxlen=max_len))\n",
    "        # predict based on current sequence\n",
    "        prediction = np.argmax(model.predict(x, verbose=False), axis=-1)\n",
    "        # update sequence\n",
    "        output = output + id_to_word[prediction[0]] + \" \"\n",
    "    return output\n",
    "    \n",
    "#predict_sequence('ivanka', 30, model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model1:\n",
    "Let's see what mr. former president thinks about democrats:\n",
    "1. democrat senators are doing a great job . i am not (LOL couldn't be more true than this)\n",
    "2. democratic states , the democrats are not going to be a total disaster .\n",
    "\n",
    "republican senators have a great job for the great state of texas . he will be a great governor ! #maga #kag and , @senatorheitkamp. and , others , the people \n",
    "gop senators must stop the flights from the united states .\n",
    "obama ’s campaign is a total disaster .\n",
    "biden has been a total disaster . i will be back soon ! #maga #kag #tcot @foxbusiness oh well , i ’m not going to be a total mess ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model 2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    layers.Embedding(input_dim=total_words, output_dim=256, mask_zero=True),\n",
    "    layers.LSTM(units=256, return_sequences=True),\n",
    "    layers.LSTM(units=256),\n",
    "    layers.Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoints2/model2.ckpt\",\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "history = model2.fit(X, labels, \n",
    "          epochs=20, \n",
    "          batch_size=batch_size, \n",
    "          verbose=True, \n",
    "          use_multiprocessing=True, \n",
    "          workers=8,\n",
    "          callbacks=[cp_callback],\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 2\n",
    "'republican senators are working hard to get the job done in the senate . we have a great state and , great healthcare ! we need strong borders and crime ! '\n",
    "'obama is a disaster for the people . he is a disaster . he is a great guy . he is a winner . he is a winner . he is a winner . he is a winner . he is a great guy and a great guy . he will be missed !\n",
    "'bernie sanders is lying to the people of the united states . he is a total mess . he is a total mess . he is a total mess . he is a total mess ! he is a total mess ! he is a corrupt politician ! a total witch hunt ! no collusion , no obstruction . the dems don ’t want to do it . he is a corrupt politician ! he is a corrupt politician ! he is a corrupt politician ! he is strong on crime , borders , and , the enemy of the people ! '\n",
    "'democrats stole election results . they are a disgrace to our country , and , we will win !\n",
    "'gop senators are working hard on the border crisis . the dems are trying to take over the border . they are now trying to take away our laws .\n",
    "'biden will bring back our country , and we are going to win the great state of texas . we need you in a second election ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
